{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7dc115d",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3234759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30000, Loss: 3.512451, Loss_u: 0.349196, Loss_f: 0.017782, Loss_u_t: 0.002710\n",
      "Epoch 1000/30000, Loss: 0.486384, Loss_u: 0.047301, Loss_f: 0.010044, Loss_u_t: 0.003330\n",
      "Epoch 2000/30000, Loss: 0.258136, Loss_u: 0.022905, Loss_f: 0.022325, Loss_u_t: 0.006758\n",
      "Epoch 3000/30000, Loss: 0.206950, Loss_u: 0.011360, Loss_f: 0.087828, Loss_u_t: 0.005524\n",
      "Epoch 4000/30000, Loss: 0.127079, Loss_u: 0.007476, Loss_f: 0.050358, Loss_u_t: 0.001964\n",
      "Epoch 4999/30000, Loss: 0.073500, Loss_u: 0.005713, Loss_f: 0.015299, Loss_u_t: 0.001068\n",
      "Epoch 5000/30000, Loss: 0.073611, Loss_u: 0.005706, Loss_f: 0.015552, Loss_u_t: 0.001000\n",
      "Epoch 6000/30000, Loss: 0.054639, Loss_u: 0.004654, Loss_f: 0.007164, Loss_u_t: 0.000936\n",
      "Epoch 7000/30000, Loss: 0.163941, Loss_u: 0.004016, Loss_f: 0.119883, Loss_u_t: 0.003897\n",
      "Epoch 8000/30000, Loss: 0.041155, Loss_u: 0.003399, Loss_f: 0.006410, Loss_u_t: 0.000754\n",
      "Epoch 9000/30000, Loss: 0.034823, Loss_u: 0.002950, Loss_f: 0.004688, Loss_u_t: 0.000630\n",
      "Epoch 10000/30000, Loss: 0.162395, Loss_u: 0.002619, Loss_f: 0.132959, Loss_u_t: 0.003244\n",
      "Epoch 11000/30000, Loss: 0.081393, Loss_u: 0.002415, Loss_f: 0.054182, Loss_u_t: 0.003064\n",
      "Epoch 12000/30000, Loss: 0.028541, Loss_u: 0.002123, Loss_f: 0.006787, Loss_u_t: 0.000521\n",
      "Epoch 13000/30000, Loss: 0.023805, Loss_u: 0.001958, Loss_f: 0.003769, Loss_u_t: 0.000453\n",
      "Epoch 14000/30000, Loss: 0.021089, Loss_u: 0.001834, Loss_f: 0.002391, Loss_u_t: 0.000357\n",
      "Epoch 15000/30000, Loss: 0.019964, Loss_u: 0.001744, Loss_f: 0.002210, Loss_u_t: 0.000314\n",
      "Epoch 16000/30000, Loss: 0.019903, Loss_u: 0.001679, Loss_f: 0.002816, Loss_u_t: 0.000300\n",
      "Epoch 17000/30000, Loss: 0.018258, Loss_u: 0.001617, Loss_f: 0.001848, Loss_u_t: 0.000240\n",
      "Epoch 18000/30000, Loss: 0.019546, Loss_u: 0.001566, Loss_f: 0.003666, Loss_u_t: 0.000215\n",
      "Epoch 19000/30000, Loss: 0.017000, Loss_u: 0.001514, Loss_f: 0.001656, Loss_u_t: 0.000199\n",
      "Epoch 20000/30000, Loss: 0.016274, Loss_u: 0.001447, Loss_f: 0.001618, Loss_u_t: 0.000188\n",
      "Epoch 21000/30000, Loss: 0.015686, Loss_u: 0.001354, Loss_f: 0.001959, Loss_u_t: 0.000185\n",
      "Epoch 22000/30000, Loss: 0.013557, Loss_u: 0.001176, Loss_f: 0.001628, Loss_u_t: 0.000170\n",
      "Epoch 23000/30000, Loss: 0.010688, Loss_u: 0.000901, Loss_f: 0.001510, Loss_u_t: 0.000168\n",
      "Epoch 24000/30000, Loss: 0.010265, Loss_u: 0.000606, Loss_f: 0.004015, Loss_u_t: 0.000193\n",
      "Epoch 25000/30000, Loss: 0.011368, Loss_u: 0.000404, Loss_f: 0.007093, Loss_u_t: 0.000233\n",
      "Epoch 26000/30000, Loss: 0.004551, Loss_u: 0.000275, Loss_f: 0.001658, Loss_u_t: 0.000144\n",
      "Epoch 27000/30000, Loss: 0.003678, Loss_u: 0.000211, Loss_f: 0.001410, Loss_u_t: 0.000162\n",
      "Epoch 28000/30000, Loss: 0.007013, Loss_u: 0.000184, Loss_f: 0.004949, Loss_u_t: 0.000227\n",
      "Epoch 29000/30000, Loss: 0.002663, Loss_u: 0.000156, Loss_f: 0.000967, Loss_u_t: 0.000140\n",
      "⏱  训练总耗时: 283.08 秒\n",
      "L2 Relative Error: 0.034524\n",
      "[0.034523927]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "from torch.autograd import grad\n",
    "torch.manual_seed(2000)\n",
    "np.random.seed(2000)\n",
    "import time\n",
    "# Define the neural network architecture\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Exact solution for the Poisson equation\n",
    "def exact_solution(x, t, c=2):\n",
    "    return torch.sin(np.pi * x) * torch.cos(c * np.pi * t) + 0.5 * torch.sin(2 * c * np.pi * x) * torch.cos(4 * c * np.pi * t)\n",
    "\n",
    "# Generate training data\n",
    "def get_data(lb, ub, Nx, Nt, Nu, Nf):\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "\n",
    "    # Initial condition u(0, x) = sin(πx) + 0.5sin(4πx)\n",
    "    u_ic = torch.sin(np.pi * x[:, 0]) + 0.5 * torch.sin(4 * np.pi * x[:, 0])  # t=0\n",
    "\n",
    "    # Boundary conditions\n",
    "    u_bc_left = torch.zeros_like(t[0, :])  # x=0\n",
    "    u_bc_right = torch.zeros_like(t[-1, :])  # x=1\n",
    "\n",
    "    # Concatenate boundary/initial conditions\n",
    "    X_u = torch.cat([ \n",
    "        torch.stack([x[:, 0], t[:, 0]], dim=1),  # Initial condition\n",
    "        torch.stack([x[0, :], t[0, :]], dim=1),  # Boundary x=0\n",
    "        torch.stack([x[-1, :], t[-1, :]], dim=1)  # Boundary x=1\n",
    "    ], dim=0)\n",
    "\n",
    "    u_u = torch.cat([u_ic, u_bc_left, u_bc_right], dim=0).reshape(-1, 1)\n",
    "    X_u = torch.cat([X_u, u_u], dim=1)\n",
    "\n",
    "    # Randomly sample Nu points from X_u\n",
    "    idx = np.random.choice(X_u.shape[0], size=Nu, replace=False)\n",
    "    X_u_sampled = X_u[idx, :]\n",
    "\n",
    "    # Latin hypercube sampling for X_f (collocation points)\n",
    "    X_f = lb + (ub - lb) * torch.tensor(lhs(2, samples=Nf), dtype=torch.float32)\n",
    "\n",
    "    # Combine collocation points and sampled boundary/initial points\n",
    "    X_train = torch.cat([X_f, X_u_sampled[:, :2]], dim=0)\n",
    "\n",
    "    return X_train, X_u_sampled\n",
    "\n",
    "# Physics loss for the Poisson equation\n",
    "def physics_loss(model, X_f, c=2):\n",
    "    X_f.requires_grad_(True)\n",
    "    u = model(X_f)\n",
    "    u_t = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = grad(u_t, X_f, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 1:2]\n",
    "    u_x = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 0:1]\n",
    "    u_xx = grad(u_x, X_f, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "\n",
    "    # Poisson equation: u_tt - c^2 * u_xx = 0\n",
    "    f = u_tt - c**2 * u_xx\n",
    "    return torch.mean(f**2)\n",
    "\n",
    "# L2 relative error\n",
    "def l2_relative_error(u_true, u_pred):\n",
    "    u_true_np = u_true.detach().numpy()\n",
    "    u_pred_np = u_pred.detach().numpy()\n",
    "    return np.linalg.norm(u_true_np - u_pred_np) / np.linalg.norm(u_true_np)\n",
    "def train(model, optimizer, X_train, X_u, epochs, Nf):\n",
    "    model.train()\n",
    "   \n",
    "    # Split the training data\n",
    "    X_f = X_train[:Nf, :]\n",
    "    X_u_train = X_u[:, :2]\n",
    "    u_u_train = X_u[:, 2:]\n",
    "\n",
    "    # Predict boundary/initial conditions\n",
    "    u_pred = model(X_u_train)\n",
    "    loss_u = torch.mean((u_pred - u_u_train)**2)\n",
    "\n",
    "    # Physics-informed loss\n",
    "    loss_f = physics_loss(model, X_f)\n",
    "\n",
    "    # Add initial condition for time derivative\n",
    "    # Extract x and t from X_u_train, where t = 0 for the initial condition\n",
    "    x_init = X_u_train[:, 0].reshape(-1, 1)\n",
    "    t_init = torch.zeros_like(x_init, requires_grad=True)  # Ensure t_init requires gradients\n",
    "    u_init_pred = model(torch.cat([x_init, t_init], dim=1))  # Predict u at t = 0\n",
    "    u_t_init_pred = grad(u_init_pred, t_init, grad_outputs=torch.ones_like(u_init_pred), create_graph=True)[0]  # Calculate time derivative u_t\n",
    "    loss_u_t = torch.mean(u_t_init_pred**2)\n",
    "    return  loss_u, loss_f, loss_u_t\n",
    "\n",
    "# Predict function\n",
    "def predict(model, x, t):\n",
    "    model.eval()\n",
    "    X = torch.stack([x.reshape(-1), t.reshape(-1)], dim=1)\n",
    "    u_pred = model(X)\n",
    "    return u_pred.reshape(x.shape)\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    lb = torch.tensor([0.0, 0.0])  # Lower bounds for x and t\n",
    "    ub = torch.tensor([1.0, 0.5])  # Upper bounds for x and t\n",
    "    Nx, Nt = 256, 100  # Discretization for x and t\n",
    "    Nu, Nf = 300, 500  # Number of boundary/initial and collocation points\n",
    "    layers = [2, 100, 100,  1]  # Neural network structure\n",
    "    epochs = 5000  # Number of training epochs\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Generate training data\n",
    "    X_train, X_u_sampled = get_data(lb, ub, Nx, Nt, Nu, Nf)\n",
    "    num_1 = [30000]\n",
    "    total_steps=30000\n",
    "    thresholds = [1e-3, 1e-3, 1e-3, 1e-3,1e-3]\n",
    "    L2_errors = []\n",
    "    start_time = time.time() \n",
    "   # Training loop\n",
    "    for i in range(len(num_1)):\n",
    "        # Initialize PINN\n",
    "        model = PINN(layers)\n",
    "        weight_history = {name: [] for name, _ in model.named_parameters()}\n",
    "        loss_spf=[]\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        start_time = time.time() \n",
    "        for epoch in range(num_1[i]):\n",
    "            optimizer.zero_grad()\n",
    "            #loss, loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "            loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "            loss = 10*loss_u + loss_f + loss_u_t\n",
    "            loss.backward()\n",
    "            loss_true=loss_u + loss_f + loss_u_t\n",
    "            loss_spf.append(loss_true.item())\n",
    "            optimizer.step()\n",
    "            for name, param in model.named_parameters():\n",
    "                weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "            if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch}/{num_1[i]}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "        \n",
    "        end_time = time.time()  # 训练结束计时\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"⏱  训练总耗时: {elapsed:.2f} 秒\")\n",
    "        # Generate test data\n",
    "        x = torch.linspace(lb[0], ub[0], Nx)\n",
    "        t = torch.linspace(lb[1], ub[1], Nt)\n",
    "        x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "        u_true = exact_solution(x, t)\n",
    "\n",
    "        # Predict the solution\n",
    "        u_pred = predict(model, x, t)\n",
    "\n",
    "        # Compute L2 relative error\n",
    "        error = l2_relative_error(u_true, u_pred)\n",
    "        L2_errors.append(error)\n",
    "        print(f\"L2 Relative Error: {error.item():.6f}\")\n",
    "        \n",
    "        \n",
    "print( L2_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659da3ec",
   "metadata": {},
   "source": [
    "# SPF-PINN-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a13f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000, Loss: 3.512451, Loss_u: 0.349196, Loss_f: 0.017782, Loss_u_t: 0.002710\n",
      "Epoch 1000/10000, Loss: 0.486384, Loss_u: 0.047301, Loss_f: 0.010044, Loss_u_t: 0.003330\n",
      "Epoch 2000/10000, Loss: 0.258136, Loss_u: 0.022905, Loss_f: 0.022325, Loss_u_t: 0.006758\n",
      "Epoch 3000/10000, Loss: 0.206950, Loss_u: 0.011360, Loss_f: 0.087828, Loss_u_t: 0.005524\n",
      "Epoch 4000/10000, Loss: 0.127079, Loss_u: 0.007476, Loss_f: 0.050358, Loss_u_t: 0.001964\n",
      "Epoch 4999/10000, Loss: 0.073500, Loss_u: 0.005713, Loss_f: 0.015299, Loss_u_t: 0.001068\n",
      "Epoch 5000/10000, Loss: 0.073611, Loss_u: 0.005706, Loss_f: 0.015552, Loss_u_t: 0.001000\n",
      "Epoch 6000/10000, Loss: 0.054639, Loss_u: 0.004654, Loss_f: 0.007164, Loss_u_t: 0.000936\n",
      "Epoch 7000/10000, Loss: 0.163941, Loss_u: 0.004016, Loss_f: 0.119883, Loss_u_t: 0.003897\n",
      "Epoch 8000/10000, Loss: 0.041155, Loss_u: 0.003399, Loss_f: 0.006410, Loss_u_t: 0.000754\n",
      "Epoch 9000/10000, Loss: 0.034823, Loss_u: 0.002950, Loss_f: 0.004688, Loss_u_t: 0.000630\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 106, 'layers.0.bias': 23, 'layers.1.weight': 4642, 'layers.1.bias': 28, 'layers.2.weight': 23, 'layers.2.bias': 0}\n",
      "掩码中值为 0 的元素个数之和 4822\n",
      "Epoch 0/20000, Loss: 0.162395, Loss_u: 0.002619, Loss_f: 0.132959, Loss_u_t: 0.003244\n",
      "Epoch 1000/20000, Loss: 0.026603, Loss_u: 0.002254, Loss_f: 0.003517, Loss_u_t: 0.000541\n",
      "Epoch 2000/20000, Loss: 0.023540, Loss_u: 0.001973, Loss_f: 0.003343, Loss_u_t: 0.000467\n",
      "Epoch 3000/20000, Loss: 0.020583, Loss_u: 0.001778, Loss_f: 0.002432, Loss_u_t: 0.000376\n",
      "Epoch 4000/20000, Loss: 0.018978, Loss_u: 0.001665, Loss_f: 0.002021, Loss_u_t: 0.000308\n",
      "Epoch 5000/20000, Loss: 0.017961, Loss_u: 0.001590, Loss_f: 0.001800, Loss_u_t: 0.000264\n",
      "Epoch 6000/20000, Loss: 0.017112, Loss_u: 0.001524, Loss_f: 0.001645, Loss_u_t: 0.000229\n",
      "Epoch 7000/20000, Loss: 0.016299, Loss_u: 0.001456, Loss_f: 0.001539, Loss_u_t: 0.000203\n",
      "Epoch 8000/20000, Loss: 0.015930, Loss_u: 0.001353, Loss_f: 0.001862, Loss_u_t: 0.000543\n",
      "Epoch 9000/20000, Loss: 0.014474, Loss_u: 0.001172, Loss_f: 0.002538, Loss_u_t: 0.000217\n",
      "Epoch 10000/20000, Loss: 0.015910, Loss_u: 0.000850, Loss_f: 0.006941, Loss_u_t: 0.000470\n",
      "Epoch 11000/20000, Loss: 0.006778, Loss_u: 0.000512, Loss_f: 0.001507, Loss_u_t: 0.000151\n",
      "Epoch 12000/20000, Loss: 0.004457, Loss_u: 0.000304, Loss_f: 0.001300, Loss_u_t: 0.000116\n",
      "Epoch 13000/20000, Loss: 0.003969, Loss_u: 0.000203, Loss_f: 0.001761, Loss_u_t: 0.000182\n",
      "Epoch 14000/20000, Loss: 0.005030, Loss_u: 0.000189, Loss_f: 0.002773, Loss_u_t: 0.000365\n",
      "Epoch 15000/20000, Loss: 0.002509, Loss_u: 0.000119, Loss_f: 0.001194, Loss_u_t: 0.000129\n",
      "Epoch 16000/20000, Loss: 0.002065, Loss_u: 0.000103, Loss_f: 0.000952, Loss_u_t: 0.000085\n",
      "Epoch 17000/20000, Loss: 0.002072, Loss_u: 0.000105, Loss_f: 0.000933, Loss_u_t: 0.000092\n",
      "Epoch 18000/20000, Loss: 0.002671, Loss_u: 0.000089, Loss_f: 0.001698, Loss_u_t: 0.000085\n",
      "Epoch 19000/20000, Loss: 0.001791, Loss_u: 0.000085, Loss_f: 0.000868, Loss_u_t: 0.000074\n",
      "Epoch 19999/20000, Loss: 0.002034, Loss_u: 0.000089, Loss_f: 0.000947, Loss_u_t: 0.000198\n",
      "⏱  训练总耗时: 296.13 秒\n",
      "L2 Relative Error: 0.023759\n",
      "[0.023759231]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "from torch.autograd import grad\n",
    "torch.manual_seed(2000)\n",
    "np.random.seed(2000)\n",
    "import time\n",
    "# Define the neural network architecture\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Exact solution for the Poisson equation\n",
    "def exact_solution(x, t, c=2):\n",
    "    return torch.sin(np.pi * x) * torch.cos(c * np.pi * t) + 0.5 * torch.sin(2 * c * np.pi * x) * torch.cos(4 * c * np.pi * t)\n",
    "\n",
    "# Generate training data\n",
    "def get_data(lb, ub, Nx, Nt, Nu, Nf):\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "\n",
    "    # Initial condition u(0, x) = sin(πx) + 0.5sin(4πx)\n",
    "    u_ic = torch.sin(np.pi * x[:, 0]) + 0.5 * torch.sin(4 * np.pi * x[:, 0])  # t=0\n",
    "\n",
    "    # Boundary conditions\n",
    "    u_bc_left = torch.zeros_like(t[0, :])  # x=0\n",
    "    u_bc_right = torch.zeros_like(t[-1, :])  # x=1\n",
    "\n",
    "    # Concatenate boundary/initial conditions\n",
    "    X_u = torch.cat([ \n",
    "        torch.stack([x[:, 0], t[:, 0]], dim=1),  # Initial condition\n",
    "        torch.stack([x[0, :], t[0, :]], dim=1),  # Boundary x=0\n",
    "        torch.stack([x[-1, :], t[-1, :]], dim=1)  # Boundary x=1\n",
    "    ], dim=0)\n",
    "\n",
    "    u_u = torch.cat([u_ic, u_bc_left, u_bc_right], dim=0).reshape(-1, 1)\n",
    "    X_u = torch.cat([X_u, u_u], dim=1)\n",
    "\n",
    "    # Randomly sample Nu points from X_u\n",
    "    idx = np.random.choice(X_u.shape[0], size=Nu, replace=False)\n",
    "    X_u_sampled = X_u[idx, :]\n",
    "\n",
    "    # Latin hypercube sampling for X_f (collocation points)\n",
    "    X_f = lb + (ub - lb) * torch.tensor(lhs(2, samples=Nf), dtype=torch.float32)\n",
    "\n",
    "    # Combine collocation points and sampled boundary/initial points\n",
    "    X_train = torch.cat([X_f, X_u_sampled[:, :2]], dim=0)\n",
    "\n",
    "    return X_train, X_u_sampled\n",
    "\n",
    "# Physics loss for the Poisson equation\n",
    "def physics_loss(model, X_f, c=2):\n",
    "    X_f.requires_grad_(True)\n",
    "    u = model(X_f)\n",
    "    u_t = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = grad(u_t, X_f, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 1:2]\n",
    "    u_x = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 0:1]\n",
    "    u_xx = grad(u_x, X_f, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "\n",
    "    # Poisson equation: u_tt - c^2 * u_xx = 0\n",
    "    f = u_tt - c**2 * u_xx\n",
    "    return torch.mean(f**2)\n",
    "\n",
    "# L2 relative error\n",
    "def l2_relative_error(u_true, u_pred):\n",
    "    u_true_np = u_true.detach().numpy()\n",
    "    u_pred_np = u_pred.detach().numpy()\n",
    "    return np.linalg.norm(u_true_np - u_pred_np) / np.linalg.norm(u_true_np)\n",
    "def train(model, optimizer, X_train, X_u, epochs, Nf):\n",
    "    model.train()\n",
    "   \n",
    "    # Split the training data\n",
    "    X_f = X_train[:Nf, :]\n",
    "    X_u_train = X_u[:, :2]\n",
    "    u_u_train = X_u[:, 2:]\n",
    "\n",
    "    # Predict boundary/initial conditions\n",
    "    u_pred = model(X_u_train)\n",
    "    loss_u = torch.mean((u_pred - u_u_train)**2)\n",
    "\n",
    "    # Physics-informed loss\n",
    "    loss_f = physics_loss(model, X_f)\n",
    "\n",
    "    # Add initial condition for time derivative\n",
    "    # Extract x and t from X_u_train, where t = 0 for the initial condition\n",
    "    x_init = X_u_train[:, 0].reshape(-1, 1)\n",
    "    t_init = torch.zeros_like(x_init, requires_grad=True)  # Ensure t_init requires gradients\n",
    "    u_init_pred = model(torch.cat([x_init, t_init], dim=1))  # Predict u at t = 0\n",
    "    u_t_init_pred = grad(u_init_pred, t_init, grad_outputs=torch.ones_like(u_init_pred), create_graph=True)[0]  # Calculate time derivative u_t\n",
    "\n",
    "    # Loss for time derivative at t = 0, enforcing u_t(0, x) = 0\n",
    "    loss_u_t = torch.mean(u_t_init_pred**2)\n",
    "\n",
    "    # Total loss, including time derivative condition\n",
    "    #loss = 10*loss_u + loss_f + loss_u_t\n",
    "    #return loss, loss_u, loss_f, loss_u_t\n",
    "    return  loss_u, loss_f, loss_u_t\n",
    "###########################################生成mask矩阵################################\n",
    "def generate_mask(weight_history, n, m, threshold):\n",
    "    weight_diffs = {}\n",
    "    for name, weights in weight_history.items():\n",
    "        if len(weights) >= n + m - 1:\n",
    "            weight_n = np.array(weights[n - 1])\n",
    "            weight_n_m = np.array(weights[n + m - 1])\n",
    "            weight_diffs[name] = np.abs(weight_n - weight_n_m)\n",
    "        else:\n",
    "            print(f\"Warning: Not enough weights for {name} to compute weight difference at n={n} and m={m}\")\n",
    "\n",
    "    masks = {}\n",
    "    for name, param in model .named_parameters():\n",
    "        weight_diff = weight_diffs.get(name, None)\n",
    "        if weight_diff is not None:\n",
    "            mask = torch.ones_like(param.data)\n",
    "            mask.view(-1)[weight_diff.flatten() < threshold] = 0\n",
    "            masks[name] = mask\n",
    "        else:\n",
    "            masks[name] = torch.ones_like(param.data)\n",
    "    # 计算掩码中值为 0 的元素个数\n",
    "    num_zeros = {}\n",
    "    total_zeros = 0\n",
    "    for name, mask in masks.items():\n",
    "        num_zeros[name] = torch.sum(torch.eq(mask, 0)).item()\n",
    "        total_zeros += num_zeros[name]  # 累加每个掩码中值为 0 的元素个数\n",
    "    print(\"掩码中值为 0 的元素个数：\", num_zeros)\n",
    "    print('掩码中值为 0 的元素个数之和',total_zeros)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "# 封装训练过程的函数\n",
    "def train_with_mask(masks, optimizer, epochs):           \n",
    "       for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "        loss = 10*loss_u + loss_f + loss_u_t\n",
    "        loss.backward()\n",
    "        loss_true=loss_u + loss_f + loss_u_t\n",
    "        loss_spf.append(loss_true.item())\n",
    "        for name, param in model.named_parameters():\n",
    "            weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "        for name, param in model.named_parameters():\n",
    "            # print(f\"Name: {name}, param.grad: {param.grad}, masks[name]: {masks[name]}\")\n",
    "            if param.requires_grad and masks[name] is not None:  # 确保掩码张量不为 None\n",
    "                if param.grad is not None:  # 检查梯度是否为 None\n",
    "                    param.grad *= masks[name].detach()\n",
    "        optimizer.step()\n",
    "        if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Predict function\n",
    "def predict(model, x, t):\n",
    "    model.eval()\n",
    "    X = torch.stack([x.reshape(-1), t.reshape(-1)], dim=1)\n",
    "    u_pred = model(X)\n",
    "    return u_pred.reshape(x.shape)\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    lb = torch.tensor([0.0, 0.0])  # Lower bounds for x and t\n",
    "    ub = torch.tensor([1.0, 0.5])  # Upper bounds for x and t\n",
    "    Nx, Nt = 256, 100  # Discretization for x and t\n",
    "    Nu, Nf = 300, 500  # Number of boundary/initial and collocation points\n",
    "    layers = [2, 100, 100,  1]  # Neural network structure\n",
    "    epochs = 5000  # Number of training epochs\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Generate training data\n",
    "    X_train, X_u_sampled = get_data(lb, ub, Nx, Nt, Nu, Nf)\n",
    "    num_1 = [10000]\n",
    "    total_steps=30000\n",
    "    thresholds = [1e-3, 1e-3, 1e-3, 1e-3,1e-3]\n",
    "    L2_errors = []\n",
    "    start_time = time.time() \n",
    "   # Training loop\n",
    "    for i in range(len(num_1)):\n",
    "        # Initialize PINN\n",
    "        model = PINN(layers)\n",
    "        weight_history = {name: [] for name, _ in model.named_parameters()}\n",
    "        loss_spf=[]\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_1[i]):\n",
    "            optimizer.zero_grad()\n",
    "            #loss, loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "            loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "            loss = 10*loss_u + loss_f + loss_u_t\n",
    "            loss.backward()\n",
    "            loss_true=loss_u + loss_f + loss_u_t\n",
    "            loss_spf.append(loss_true.item())\n",
    "            optimizer.step()\n",
    "            for name, param in model.named_parameters():\n",
    "                weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "            if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch}/{num_1[i]}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "\n",
    "\n",
    "        \n",
    "        #######################################\n",
    "        n, m = num_1[i]-1000, 1000\n",
    "        masks = generate_mask(weight_history, n, m, thresholds[i])\n",
    "        epochs =  total_steps- num_1[i]\n",
    "        train_with_mask(masks, optimizer, epochs)\n",
    "        \n",
    "        end_time = time.time()  # 训练结束计时\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"⏱  训练总耗时: {elapsed:.2f} 秒\")\n",
    "        # Generate test data\n",
    "        x = torch.linspace(lb[0], ub[0], Nx)\n",
    "        t = torch.linspace(lb[1], ub[1], Nt)\n",
    "        x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "        u_true = exact_solution(x, t)\n",
    "\n",
    "        # Predict the solution\n",
    "        u_pred = predict(model, x, t)\n",
    "\n",
    "        # Compute L2 relative error\n",
    "        error = l2_relative_error(u_true, u_pred)\n",
    "        L2_errors.append(error)\n",
    "        print(f\"L2 Relative Error: {error.item():.6f}\")\n",
    "        \n",
    "        \n",
    "print( L2_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc75728",
   "metadata": {},
   "source": [
    "# SPF-PINN-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6c1780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000, Loss: 3.512451, Loss_u: 0.349196, Loss_f: 0.017782, Loss_u_t: 0.002710\n",
      "Epoch 1000/10000, Loss: 0.486384, Loss_u: 0.047301, Loss_f: 0.010044, Loss_u_t: 0.003330\n",
      "Epoch 2000/10000, Loss: 0.258136, Loss_u: 0.022905, Loss_f: 0.022325, Loss_u_t: 0.006758\n",
      "Epoch 3000/10000, Loss: 0.206950, Loss_u: 0.011360, Loss_f: 0.087828, Loss_u_t: 0.005524\n",
      "Epoch 4000/10000, Loss: 0.127079, Loss_u: 0.007476, Loss_f: 0.050358, Loss_u_t: 0.001964\n",
      "Epoch 4999/10000, Loss: 0.073500, Loss_u: 0.005713, Loss_f: 0.015299, Loss_u_t: 0.001068\n",
      "Epoch 5000/10000, Loss: 0.073611, Loss_u: 0.005706, Loss_f: 0.015552, Loss_u_t: 0.001000\n",
      "Epoch 6000/10000, Loss: 0.054639, Loss_u: 0.004654, Loss_f: 0.007164, Loss_u_t: 0.000936\n",
      "Epoch 7000/10000, Loss: 0.163941, Loss_u: 0.004016, Loss_f: 0.119883, Loss_u_t: 0.003897\n",
      "Epoch 8000/10000, Loss: 0.041155, Loss_u: 0.003399, Loss_f: 0.006410, Loss_u_t: 0.000754\n",
      "Epoch 9000/10000, Loss: 0.034823, Loss_u: 0.002950, Loss_f: 0.004688, Loss_u_t: 0.000630\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 106, 'layers.0.bias': 23, 'layers.1.weight': 4642, 'layers.1.bias': 28, 'layers.2.weight': 23, 'layers.2.bias': 0}\n",
      "掩码中值为 0 的元素个数之和 4822\n",
      "Epoch 0/5000, Loss: 0.162395, Loss_u: 0.002619, Loss_f: 0.132959, Loss_u_t: 0.003244\n",
      "Epoch 1000/5000, Loss: 0.026603, Loss_u: 0.002254, Loss_f: 0.003517, Loss_u_t: 0.000541\n",
      "Epoch 2000/5000, Loss: 0.023540, Loss_u: 0.001973, Loss_f: 0.003343, Loss_u_t: 0.000467\n",
      "Epoch 3000/5000, Loss: 0.020583, Loss_u: 0.001778, Loss_f: 0.002432, Loss_u_t: 0.000376\n",
      "Epoch 4000/5000, Loss: 0.018978, Loss_u: 0.001665, Loss_f: 0.002021, Loss_u_t: 0.000308\n",
      "Epoch 4999/5000, Loss: 0.017935, Loss_u: 0.001588, Loss_f: 0.001779, Loss_u_t: 0.000274\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 143, 'layers.0.bias': 41, 'layers.1.weight': 6213, 'layers.1.bias': 44, 'layers.2.weight': 38, 'layers.2.bias': 1}\n",
      "掩码中值为 0 的元素个数之和 6480\n",
      "Epoch 0/5000, Loss: 0.017961, Loss_u: 0.001590, Loss_f: 0.001800, Loss_u_t: 0.000264\n",
      "Epoch 1000/5000, Loss: 0.016878, Loss_u: 0.001503, Loss_f: 0.001625, Loss_u_t: 0.000219\n",
      "Epoch 2000/5000, Loss: 0.017352, Loss_u: 0.001382, Loss_f: 0.003306, Loss_u_t: 0.000222\n",
      "Epoch 3000/5000, Loss: 0.013037, Loss_u: 0.001088, Loss_f: 0.001932, Loss_u_t: 0.000220\n",
      "Epoch 4000/5000, Loss: 0.007754, Loss_u: 0.000618, Loss_f: 0.001419, Loss_u_t: 0.000152\n",
      "Epoch 4999/5000, Loss: 0.004867, Loss_u: 0.000329, Loss_f: 0.001453, Loss_u_t: 0.000129\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 159, 'layers.0.bias': 49, 'layers.1.weight': 6984, 'layers.1.bias': 55, 'layers.2.weight': 48, 'layers.2.bias': 1}\n",
      "掩码中值为 0 的元素个数之和 7296\n",
      "Epoch 0/10000, Loss: 0.004868, Loss_u: 0.000328, Loss_f: 0.001450, Loss_u_t: 0.000135\n",
      "Epoch 1000/10000, Loss: 0.003230, Loss_u: 0.000186, Loss_f: 0.001256, Loss_u_t: 0.000119\n",
      "Epoch 2000/10000, Loss: 0.003507, Loss_u: 0.000129, Loss_f: 0.002047, Loss_u_t: 0.000171\n",
      "Epoch 3000/10000, Loss: 0.002036, Loss_u: 0.000095, Loss_f: 0.000971, Loss_u_t: 0.000110\n",
      "Epoch 4000/10000, Loss: 0.002069, Loss_u: 0.000082, Loss_f: 0.001151, Loss_u_t: 0.000102\n",
      "Epoch 5000/10000, Loss: 0.001697, Loss_u: 0.000075, Loss_f: 0.000857, Loss_u_t: 0.000091\n",
      "Epoch 6000/10000, Loss: 0.001684, Loss_u: 0.000070, Loss_f: 0.000895, Loss_u_t: 0.000085\n",
      "Epoch 7000/10000, Loss: 0.001607, Loss_u: 0.000067, Loss_f: 0.000861, Loss_u_t: 0.000078\n",
      "Epoch 8000/10000, Loss: 0.001449, Loss_u: 0.000064, Loss_f: 0.000735, Loss_u_t: 0.000074\n",
      "Epoch 9000/10000, Loss: 0.001422, Loss_u: 0.000061, Loss_f: 0.000741, Loss_u_t: 0.000074\n",
      "Epoch 9999/10000, Loss: 0.001308, Loss_u: 0.000058, Loss_f: 0.000669, Loss_u_t: 0.000061\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 177, 'layers.0.bias': 56, 'layers.1.weight': 8279, 'layers.1.bias': 73, 'layers.2.weight': 59, 'layers.2.bias': 1}\n",
      "掩码中值为 0 的元素个数之和 8645\n",
      "Epoch 0/5000, Loss: 0.001309, Loss_u: 0.000058, Loss_f: 0.000669, Loss_u_t: 0.000061\n",
      "Epoch 1000/5000, Loss: 0.001244, Loss_u: 0.000054, Loss_f: 0.000646, Loss_u_t: 0.000055\n",
      "Epoch 2000/5000, Loss: 0.001179, Loss_u: 0.000051, Loss_f: 0.000620, Loss_u_t: 0.000049\n",
      "Epoch 3000/5000, Loss: 0.001141, Loss_u: 0.000048, Loss_f: 0.000612, Loss_u_t: 0.000047\n",
      "Epoch 4000/5000, Loss: 0.001216, Loss_u: 0.000047, Loss_f: 0.000654, Loss_u_t: 0.000095\n",
      "Epoch 4999/5000, Loss: 0.001120, Loss_u: 0.000045, Loss_f: 0.000580, Loss_u_t: 0.000095\n",
      "⏱  训练总耗时: 353.57 秒\n",
      "L2 Relative Error: 0.016156\n",
      "[0.016156241]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "from torch.autograd import grad\n",
    "torch.manual_seed(2000)\n",
    "np.random.seed(2000)\n",
    "import time\n",
    "# Define the neural network architecture\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Exact solution for the Poisson equation\n",
    "def exact_solution(x, t, c=2):\n",
    "    return torch.sin(np.pi * x) * torch.cos(c * np.pi * t) + 0.5 * torch.sin(2 * c * np.pi * x) * torch.cos(4 * c * np.pi * t)\n",
    "\n",
    "# Generate training data\n",
    "def get_data(lb, ub, Nx, Nt, Nu, Nf):\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "\n",
    "    # Initial condition u(0, x) = sin(πx) + 0.5sin(4πx)\n",
    "    u_ic = torch.sin(np.pi * x[:, 0]) + 0.5 * torch.sin(4 * np.pi * x[:, 0])  # t=0\n",
    "\n",
    "    # Boundary conditions\n",
    "    u_bc_left = torch.zeros_like(t[0, :])  # x=0\n",
    "    u_bc_right = torch.zeros_like(t[-1, :])  # x=1\n",
    "\n",
    "    # Concatenate boundary/initial conditions\n",
    "    X_u = torch.cat([ \n",
    "        torch.stack([x[:, 0], t[:, 0]], dim=1),  # Initial condition\n",
    "        torch.stack([x[0, :], t[0, :]], dim=1),  # Boundary x=0\n",
    "        torch.stack([x[-1, :], t[-1, :]], dim=1)  # Boundary x=1\n",
    "    ], dim=0)\n",
    "\n",
    "    u_u = torch.cat([u_ic, u_bc_left, u_bc_right], dim=0).reshape(-1, 1)\n",
    "    X_u = torch.cat([X_u, u_u], dim=1)\n",
    "\n",
    "    # Randomly sample Nu points from X_u\n",
    "    idx = np.random.choice(X_u.shape[0], size=Nu, replace=False)\n",
    "    X_u_sampled = X_u[idx, :]\n",
    "\n",
    "    # Latin hypercube sampling for X_f (collocation points)\n",
    "    X_f = lb + (ub - lb) * torch.tensor(lhs(2, samples=Nf), dtype=torch.float32)\n",
    "\n",
    "    # Combine collocation points and sampled boundary/initial points\n",
    "    X_train = torch.cat([X_f, X_u_sampled[:, :2]], dim=0)\n",
    "\n",
    "    return X_train, X_u_sampled\n",
    "\n",
    "# Physics loss for the Poisson equation\n",
    "def physics_loss(model, X_f, c=2):\n",
    "    X_f.requires_grad_(True)\n",
    "    u = model(X_f)\n",
    "    u_t = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = grad(u_t, X_f, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 1:2]\n",
    "    u_x = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 0:1]\n",
    "    u_xx = grad(u_x, X_f, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "\n",
    "    # Poisson equation: u_tt - c^2 * u_xx = 0\n",
    "    f = u_tt - c**2 * u_xx\n",
    "    return torch.mean(f**2)\n",
    "\n",
    "# L2 relative error\n",
    "def l2_relative_error(u_true, u_pred):\n",
    "    u_true_np = u_true.detach().numpy()\n",
    "    u_pred_np = u_pred.detach().numpy()\n",
    "    return np.linalg.norm(u_true_np - u_pred_np) / np.linalg.norm(u_true_np)\n",
    "def train(model, optimizer, X_train, X_u, epochs, Nf):\n",
    "    model.train()\n",
    "   \n",
    "    # Split the training data\n",
    "    X_f = X_train[:Nf, :]\n",
    "    X_u_train = X_u[:, :2]\n",
    "    u_u_train = X_u[:, 2:]\n",
    "\n",
    "    # Predict boundary/initial conditions\n",
    "    u_pred = model(X_u_train)\n",
    "    loss_u = torch.mean((u_pred - u_u_train)**2)\n",
    "\n",
    "    # Physics-informed loss\n",
    "    loss_f = physics_loss(model, X_f)\n",
    "\n",
    "    # Add initial condition for time derivative\n",
    "    # Extract x and t from X_u_train, where t = 0 for the initial condition\n",
    "    x_init = X_u_train[:, 0].reshape(-1, 1)\n",
    "    t_init = torch.zeros_like(x_init, requires_grad=True)  # Ensure t_init requires gradients\n",
    "    u_init_pred = model(torch.cat([x_init, t_init], dim=1))  # Predict u at t = 0\n",
    "    u_t_init_pred = grad(u_init_pred, t_init, grad_outputs=torch.ones_like(u_init_pred), create_graph=True)[0]  # Calculate time derivative u_t\n",
    "\n",
    "    # Loss for time derivative at t = 0, enforcing u_t(0, x) = 0\n",
    "    loss_u_t = torch.mean(u_t_init_pred**2)\n",
    "\n",
    "    # Total loss, including time derivative condition\n",
    "    #loss = 10*loss_u + loss_f + loss_u_t\n",
    "    #return loss, loss_u, loss_f, loss_u_t\n",
    "    return  loss_u, loss_f, loss_u_t\n",
    "\n",
    "def generate_mask(weight_history, n, m, threshold):\n",
    "    weight_diffs = {}\n",
    "    for name, weights in weight_history.items():\n",
    "        if len(weights) >= n + m - 1:\n",
    "            weight_n = np.array(weights[n - 1])\n",
    "            weight_n_m = np.array(weights[n + m - 1])\n",
    "            weight_diffs[name] = np.abs(weight_n - weight_n_m)\n",
    "        else:\n",
    "            print(f\"Warning: Not enough weights for {name} to compute weight difference at n={n} and m={m}\")\n",
    "\n",
    "    masks = {}\n",
    "    for name, param in model .named_parameters():\n",
    "        weight_diff = weight_diffs.get(name, None)\n",
    "        if weight_diff is not None:\n",
    "            mask = torch.ones_like(param.data)\n",
    "            mask.view(-1)[weight_diff.flatten() < threshold] = 0\n",
    "            masks[name] = mask\n",
    "        else:\n",
    "            masks[name] = torch.ones_like(param.data)\n",
    "    # 计算掩码中值为 0 的元素个数\n",
    "    num_zeros = {}\n",
    "    total_zeros = 0\n",
    "    for name, mask in masks.items():\n",
    "        num_zeros[name] = torch.sum(torch.eq(mask, 0)).item()\n",
    "        total_zeros += num_zeros[name]  # 累加每个掩码中值为 0 的元素个数\n",
    "    print(\"掩码中值为 0 的元素个数：\", num_zeros)\n",
    "    print('掩码中值为 0 的元素个数之和',total_zeros)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "\n",
    "def train_with_mask(masks, optimizer, epochs):           \n",
    "       for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "        loss = 10*loss_u + loss_f + loss_u_t\n",
    "        loss.backward()\n",
    "        loss_true=loss_u + loss_f + loss_u_t\n",
    "        loss_spf.append(loss_true.item())\n",
    "        for name, param in model.named_parameters():\n",
    "            weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "        for name, param in model.named_parameters():\n",
    "            # print(f\"Name: {name}, param.grad: {param.grad}, masks[name]: {masks[name]}\")\n",
    "            if param.requires_grad and masks[name] is not None:  # 确保掩码张量不为 None\n",
    "                if param.grad is not None:  # 检查梯度是否为 None\n",
    "                    param.grad *= masks[name].detach()\n",
    "        optimizer.step()\n",
    "        if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Predict function\n",
    "def predict(model, x, t):\n",
    "    model.eval()\n",
    "    X = torch.stack([x.reshape(-1), t.reshape(-1)], dim=1)\n",
    "    u_pred = model(X)\n",
    "    return u_pred.reshape(x.shape)\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    lb = torch.tensor([0.0, 0.0])  # Lower bounds for x and t\n",
    "    ub = torch.tensor([1.0, 0.5])  # Upper bounds for x and t\n",
    "    Nx, Nt = 256, 100  # Discretization for x and t\n",
    "    Nu, Nf = 300, 500  # Number of boundary/initial and collocation points\n",
    "    layers = [2, 100, 100,  1]  # Neural network structure\n",
    "    epochs = 5000  # Number of training epochs\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Generate training data\n",
    "    X_train, X_u_sampled = get_data(lb, ub, Nx, Nt, Nu, Nf)\n",
    "    num_1 = [10000]\n",
    "    num_2 = [15000]\n",
    "    num_3 =[20000]\n",
    "    num_4=[25000]\n",
    "    total_steps=30000\n",
    "    thresholds = [1e-3, 1e-3, 1e-3, 1e-3,1e-3]\n",
    "    L2_errors = []\n",
    "    start_time = time.time() \n",
    "   # Training loop\n",
    "    for i in range(len(num_1)):\n",
    "        # Initialize PINN\n",
    "        model = PINN(layers)\n",
    "        weight_history = {name: [] for name, _ in model.named_parameters()}\n",
    "        loss_spf=[]\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_1[i]):\n",
    "            optimizer.zero_grad()\n",
    "            #loss, loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "            loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "            loss = 10*loss_u + loss_f + loss_u_t\n",
    "            loss.backward()\n",
    "            loss_true=loss_u + loss_f + loss_u_t\n",
    "            loss_spf.append(loss_true.item())\n",
    "            optimizer.step()\n",
    "            for name, param in model.named_parameters():\n",
    "                weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "            if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "                print(f\"Epoch {epoch}/{num_1[i]}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "\n",
    "\n",
    "        \n",
    "        #######################################\n",
    "        n, m = num_1[i]-1000, 1000\n",
    "        masks = generate_mask(weight_history, n, m, thresholds[i])\n",
    "        epochs = num_2[i] - num_1[i]\n",
    "        train_with_mask(masks, optimizer, epochs)\n",
    "\n",
    "        n, m = num_2[i]-1000, 1000\n",
    "        masks = generate_mask(weight_history, n, m, thresholds[i])\n",
    "        epochs =num_3[i]- num_2[i]\n",
    "        train_with_mask(masks, optimizer,epochs)\n",
    "\n",
    "        n, m = num_3[i]-1000, 1000\n",
    "        masks = generate_mask(weight_history, n, m, thresholds[i])\n",
    "        epochs =total_steps- num_3[i]\n",
    "        train_with_mask(masks, optimizer, epochs)\n",
    "\n",
    "        n, m = num_4[i]-1000, 1000\n",
    "        masks = generate_mask(weight_history, n, m, thresholds[i])\n",
    "        epochs = total_steps- num_4[i]\n",
    "        train_with_mask(masks, optimizer, epochs)\n",
    "        \n",
    "        end_time = time.time()  # 训练结束计时\n",
    "        elapsed = end_time - start_time\n",
    "        print(f\"⏱  训练总耗时: {elapsed:.2f} 秒\")\n",
    "        # Generate test data\n",
    "        x = torch.linspace(lb[0], ub[0], Nx)\n",
    "        t = torch.linspace(lb[1], ub[1], Nt)\n",
    "        x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "        u_true = exact_solution(x, t)\n",
    "\n",
    "        # Predict the solution\n",
    "        u_pred = predict(model, x, t)\n",
    "\n",
    "        # Compute L2 relative error\n",
    "        error = l2_relative_error(u_true, u_pred)\n",
    "        L2_errors.append(error)\n",
    "        print(f\"L2 Relative Error: {error.item():.6f}\")\n",
    "        \n",
    "        \n",
    "print( L2_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25e20c",
   "metadata": {},
   "source": [
    "# PINN+NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451b16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50000, Loss: 2.349141, Loss_u: 0.229212, Loss_f: 0.015412, Loss_u_t: 0.041612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\gputf\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\dell\\Anaconda3\\envs\\gputf\\lib\\site-packages\\ipykernel_launcher.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 1000/50000, Loss: 0.593615, Loss_u: 0.058278, Loss_f: 0.004166, Loss_u_t: 0.006663\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 2000/50000, Loss: 0.527667, Loss_u: 0.051727, Loss_f: 0.003683, Loss_u_t: 0.006712\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 3000/50000, Loss: 0.271646, Loss_u: 0.024917, Loss_f: 0.020779, Loss_u_t: 0.001694\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4000/50000, Loss: 0.162207, Loss_u: 0.014276, Loss_f: 0.015498, Loss_u_t: 0.003951\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 5000/50000, Loss: 0.121761, Loss_u: 0.010536, Loss_f: 0.012613, Loss_u_t: 0.003786\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 6000/50000, Loss: 0.101516, Loss_u: 0.008150, Loss_f: 0.016169, Loss_u_t: 0.003843\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 7000/50000, Loss: 0.074848, Loss_u: 0.006570, Loss_f: 0.005587, Loss_u_t: 0.003556\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 8000/50000, Loss: 0.061642, Loss_u: 0.005342, Loss_f: 0.005025, Loss_u_t: 0.003193\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 9000/50000, Loss: 0.048947, Loss_u: 0.004101, Loss_f: 0.005095, Loss_u_t: 0.002843\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 10000/50000, Loss: 0.038143, Loss_u: 0.002991, Loss_f: 0.005712, Loss_u_t: 0.002517\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 11000/50000, Loss: 0.031977, Loss_u: 0.002382, Loss_f: 0.006061, Loss_u_t: 0.002092\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 12000/50000, Loss: 0.027504, Loss_u: 0.002041, Loss_f: 0.005384, Loss_u_t: 0.001713\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 13000/50000, Loss: 0.027672, Loss_u: 0.001857, Loss_f: 0.007697, Loss_u_t: 0.001408\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 14000/50000, Loss: 0.023793, Loss_u: 0.001750, Loss_f: 0.005181, Loss_u_t: 0.001114\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 15000/50000, Loss: 0.021670, Loss_u: 0.001682, Loss_f: 0.003972, Loss_u_t: 0.000881\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 16000/50000, Loss: 0.020599, Loss_u: 0.001631, Loss_f: 0.003561, Loss_u_t: 0.000730\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 17000/50000, Loss: 0.020451, Loss_u: 0.001589, Loss_f: 0.003914, Loss_u_t: 0.000649\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 18000/50000, Loss: 0.023099, Loss_u: 0.001540, Loss_f: 0.007153, Loss_u_t: 0.000544\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19000/50000, Loss: 0.021130, Loss_u: 0.001503, Loss_f: 0.005486, Loss_u_t: 0.000611\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 20000/50000, Loss: 0.019926, Loss_u: 0.001461, Loss_f: 0.004795, Loss_u_t: 0.000518\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 21000/50000, Loss: 0.016844, Loss_u: 0.001417, Loss_f: 0.002311, Loss_u_t: 0.000366\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 22000/50000, Loss: 0.017600, Loss_u: 0.001362, Loss_f: 0.003642, Loss_u_t: 0.000341\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 23000/50000, Loss: 0.015293, Loss_u: 0.001275, Loss_f: 0.002255, Loss_u_t: 0.000284\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 24000/50000, Loss: 0.016273, Loss_u: 0.001164, Loss_f: 0.004352, Loss_u_t: 0.000283\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 25000/50000, Loss: 0.013395, Loss_u: 0.001023, Loss_f: 0.002930, Loss_u_t: 0.000236\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 26000/50000, Loss: 0.010931, Loss_u: 0.000865, Loss_f: 0.002090, Loss_u_t: 0.000189\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 27000/50000, Loss: 0.011786, Loss_u: 0.000703, Loss_f: 0.004563, Loss_u_t: 0.000197\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 28000/50000, Loss: 0.022947, Loss_u: 0.000572, Loss_f: 0.016725, Loss_u_t: 0.000505\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 29000/50000, Loss: 0.006602, Loss_u: 0.000463, Loss_f: 0.001840, Loss_u_t: 0.000134\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 30000/50000, Loss: 0.005660, Loss_u: 0.000379, Loss_f: 0.001745, Loss_u_t: 0.000124\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 31000/50000, Loss: 0.005991, Loss_u: 0.000310, Loss_f: 0.002723, Loss_u_t: 0.000173\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 32000/50000, Loss: 0.004353, Loss_u: 0.000261, Loss_f: 0.001618, Loss_u_t: 0.000127\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 33000/50000, Loss: 0.040427, Loss_u: 0.000239, Loss_f: 0.035370, Loss_u_t: 0.002667\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 34000/50000, Loss: 0.004413, Loss_u: 0.000203, Loss_f: 0.002244, Loss_u_t: 0.000140\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 35000/50000, Loss: 0.039213, Loss_u: 0.000192, Loss_f: 0.036626, Loss_u_t: 0.000671\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 36000/50000, Loss: 0.003734, Loss_u: 0.000167, Loss_f: 0.001952, Loss_u_t: 0.000107\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 37000/50000, Loss: 0.019842, Loss_u: 0.000162, Loss_f: 0.018105, Loss_u_t: 0.000116\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38000/50000, Loss: 0.002991, Loss_u: 0.000144, Loss_f: 0.001462, Loss_u_t: 0.000093\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 39000/50000, Loss: 0.002489, Loss_u: 0.000134, Loss_f: 0.001057, Loss_u_t: 0.000092\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 40000/50000, Loss: 0.003113, Loss_u: 0.000128, Loss_f: 0.001734, Loss_u_t: 0.000098\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 41000/50000, Loss: 0.012794, Loss_u: 0.000124, Loss_f: 0.011414, Loss_u_t: 0.000142\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 42000/50000, Loss: 0.003891, Loss_u: 0.000114, Loss_f: 0.002645, Loss_u_t: 0.000104\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 43000/50000, Loss: 0.010221, Loss_u: 0.000111, Loss_f: 0.008941, Loss_u_t: 0.000172\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 44000/50000, Loss: 0.002091, Loss_u: 0.000105, Loss_f: 0.000965, Loss_u_t: 0.000080\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 45000/50000, Loss: 0.018083, Loss_u: 0.000106, Loss_f: 0.016903, Loss_u_t: 0.000120\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 46000/50000, Loss: 0.002778, Loss_u: 0.000097, Loss_f: 0.001681, Loss_u_t: 0.000126\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 47000/50000, Loss: 0.005048, Loss_u: 0.000096, Loss_f: 0.004001, Loss_u_t: 0.000088\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 48000/50000, Loss: 0.009424, Loss_u: 0.000099, Loss_f: 0.008298, Loss_u_t: 0.000136\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 49000/50000, Loss: 0.001846, Loss_u: 0.000089, Loss_f: 0.000889, Loss_u_t: 0.000067\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 49999/50000, Loss: 0.001492, Loss_u: 0.000087, Loss_f: 0.000555, Loss_u_t: 0.000064\n",
      "L2 Relative Error: 0.025453\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "from torch.autograd import grad\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Exact solution for the Poisson equation\n",
    "def exact_solution(x, t, c=2):\n",
    "    return torch.sin(np.pi * x) * torch.cos(c * np.pi * t) + 0.5 * torch.sin(2 * c * np.pi * x) * torch.cos(4 * c * np.pi * t)\n",
    "\n",
    "# Generate training data\n",
    "def get_data(lb, ub, Nx, Nt, Nu, Nf):\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "\n",
    "    # Initial condition u(0, x) = sin(πx) + 0.5sin(4πx)\n",
    "    u_ic = torch.sin(np.pi * x[:, 0]) + 0.5 * torch.sin(4 * np.pi * x[:, 0])  # t=0\n",
    "\n",
    "    # Boundary conditions\n",
    "    u_bc_left = torch.zeros_like(t[0, :])  # x=0\n",
    "    u_bc_right = torch.zeros_like(t[-1, :])  # x=1\n",
    "\n",
    "    # Concatenate boundary/initial conditions\n",
    "    X_u = torch.cat([ \n",
    "        torch.stack([x[:, 0], t[:, 0]], dim=1),  # Initial condition\n",
    "        torch.stack([x[0, :], t[0, :]], dim=1),  # Boundary x=0\n",
    "        torch.stack([x[-1, :], t[-1, :]], dim=1)  # Boundary x=1\n",
    "    ], dim=0)\n",
    "\n",
    "    u_u = torch.cat([u_ic, u_bc_left, u_bc_right], dim=0).reshape(-1, 1)\n",
    "    X_u = torch.cat([X_u, u_u], dim=1)\n",
    "\n",
    "    # Randomly sample Nu points from X_u\n",
    "    idx = np.random.choice(X_u.shape[0], size=Nu, replace=False)\n",
    "    X_u_sampled = X_u[idx, :]\n",
    "\n",
    "    # Latin hypercube sampling for X_f (collocation points)\n",
    "    X_f = lb + (ub - lb) * torch.tensor(lhs(2, samples=Nf), dtype=torch.float32)\n",
    "\n",
    "    # Combine collocation points and sampled boundary/initial points\n",
    "    X_train = torch.cat([X_f, X_u_sampled[:, :2]], dim=0)\n",
    "\n",
    "    return X_train, X_u_sampled\n",
    "\n",
    "# Physics loss for the Poisson equation\n",
    "def physics_loss(model, X_f, c=2):\n",
    "    X_f.requires_grad_(True)\n",
    "    u = model(X_f)\n",
    "    u_t = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = grad(u_t, X_f, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 1:2]\n",
    "    u_x = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 0:1]\n",
    "    u_xx = grad(u_x, X_f, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "\n",
    "    # Poisson equation: u_tt - c^2 * u_xx = 0\n",
    "    f = u_tt - c**2 * u_xx\n",
    "    return torch.mean(f**2)\n",
    "\n",
    "# L2 relative error\n",
    "def l2_relative_error(u_true, u_pred):\n",
    "    u_true_np = u_true.detach().numpy()\n",
    "    u_pred_np = u_pred.detach().numpy()\n",
    "    return np.linalg.norm(u_true_np - u_pred_np) / np.linalg.norm(u_true_np)\n",
    "def train(model, optimizer, X_train, X_u, epochs, Nf):\n",
    "    model.train()\n",
    "   \n",
    "    # Split the training data\n",
    "    X_f = X_train[:Nf, :]\n",
    "    X_u_train = X_u[:, :2]\n",
    "    u_u_train = X_u[:, 2:]\n",
    "\n",
    "    # Predict boundary/initial conditions\n",
    "    u_pred = model(X_u_train)\n",
    "    loss_u = torch.mean((u_pred - u_u_train)**2)\n",
    "\n",
    "    # Physics-informed loss\n",
    "    loss_f = physics_loss(model, X_f)\n",
    "\n",
    "    # Add initial condition for time derivative\n",
    "    # Extract x and t from X_u_train, where t = 0 for the initial condition\n",
    "    x_init = X_u_train[:, 0].reshape(-1, 1)\n",
    "    t_init = torch.zeros_like(x_init, requires_grad=True)  # Ensure t_init requires gradients\n",
    "    u_init_pred = model(torch.cat([x_init, t_init], dim=1))  # Predict u at t = 0\n",
    "    u_t_init_pred = grad(u_init_pred, t_init, grad_outputs=torch.ones_like(u_init_pred), create_graph=True)[0]  # Calculate time derivative u_t\n",
    "\n",
    "    # Loss for time derivative at t = 0, enforcing u_t(0, x) = 0\n",
    "    loss_u_t = torch.mean(u_t_init_pred**2)\n",
    "\n",
    "    # Total loss, including time derivative condition\n",
    "    loss = 10*loss_u + loss_f + loss_u_t\n",
    "    return loss, loss_u, loss_f, loss_u_t\n",
    "\n",
    "\n",
    "\n",
    "# Predict function\n",
    "def predict(model, x, t):\n",
    "    model.eval()\n",
    "    X = torch.stack([x.reshape(-1), t.reshape(-1)], dim=1)\n",
    "    u_pred = model(X)\n",
    "    return u_pred.reshape(x.shape)\n",
    "###################################################################################################\n",
    "#########################################--NTK--#######################################################\n",
    "def  compute_pde_jacobian(model, X, create_graph=True, c=2):\n",
    "    \"\"\"\n",
    "    计算 KdV 方程残差的雅可比矩阵\n",
    "    model: 神经网络模型\n",
    "    X: 输入点，形状为 (N, 2)，第一列是 x，第二列是 t\n",
    "    create_graph: 是否创建计算图，默认 True\n",
    "    \"\"\"\n",
    "    X = torch.tensor(X, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    # 模型预测 u\n",
    "    u = model(X)\n",
    "\n",
    "    # 计算一阶导数 u_x, u_t\n",
    "    grad_u = torch.autograd.grad(\n",
    "        outputs=u.sum(),\n",
    "        inputs=X,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    u_x = grad_u[:, 0:1]\n",
    "    u_t = grad_u[:, 1:2]\n",
    "    \n",
    "    # 计算二阶导数 u_xx\n",
    "    u_xx = torch.autograd.grad(\n",
    "        outputs=u_x.sum(),\n",
    "        inputs=X,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, 1:2]\n",
    "    u_tt = torch.autograd.grad(\n",
    "        outputs=u_t.sum(),\n",
    "        inputs=X,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, 0:1]\n",
    "    \n",
    "\n",
    "    f = u_tt -c**2*u_xx\n",
    "\n",
    "    # 计算残差的雅可比矩阵\n",
    "    jacobian_list = []\n",
    "    for i in range(f.size(0)):\n",
    "        grad_outputs = torch.ones_like(f[i])\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=f[i],\n",
    "            inputs=model.parameters(),\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        # 处理 None 的梯度\n",
    "        valid_grads = [g if g is not None else torch.zeros_like(p) \n",
    "                       for g, p in zip(grads, model.parameters())]\n",
    "        jacobian_list.append(torch.cat([g.view(-1) for g in valid_grads]))\n",
    "\n",
    "    return torch.stack(jacobian_list)\n",
    "def  compute_jacobian_pinn(model, X_u, create_graph=True):\n",
    "    \"\"\"\n",
    "    计算 KdV 方程初边值条件的雅可比矩阵\n",
    "    model: 神经网络模型\n",
    "    X_u: 初边值条件的输入点 (x, t)，形状为 (N, 2)\n",
    "    create_graph: 是否创建计算图，默认 True\n",
    "    \"\"\"\n",
    "    X_u = torch.tensor(X_u, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    # 模型预测初边值条件的 u\n",
    "    u = model(X_u)\n",
    "    \n",
    "    # 计算初边值条件的雅可比矩阵\n",
    "    jacobian_list = []\n",
    "    for i in range(u.size(0)):\n",
    "        grad_outputs = torch.ones_like(u[i])\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=u[i],\n",
    "            inputs=model.parameters(),\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        # 处理 None 的梯度\n",
    "        valid_grads = [g if g is not None else torch.zeros_like(p) \n",
    "                       for g, p in zip(grads, model.parameters())]\n",
    "        jacobian_list.append(torch.cat([g.view(-1) for g in valid_grads]))\n",
    "    \n",
    "    return torch.stack(jacobian_list)\n",
    "\n",
    "def compute_all_eigenvalues(K_uu, K_rr, K):\n",
    "\n",
    "    # 计算Kuu的特征值\n",
    "    eigenvalues_uu = np.sort(np.real(np.linalg.eigvals(K_uu.detach().numpy())))[::-1]\n",
    "    \n",
    "    # 计算Krr的特征值\n",
    "    eigenvalues_rr = np.sort(np.real(np.linalg.eigvals(K_rr.detach().numpy())))[::-1]\n",
    "    \n",
    "    # 计算完整K矩阵的特征值\n",
    "    eigenvalues_k = np.sort(np.real(np.linalg.eigvals(K.detach().numpy())))[::-1]\n",
    "    \n",
    "    return eigenvalues_uu, eigenvalues_rr, eigenvalues_k\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "        # 记录不同矩阵的特征值演化\n",
    "    eigenvalues_uu_history = []\n",
    "    eigenvalues_rr_history = []\n",
    "    eigenvalues_k_history = []\n",
    "    interval = 500\n",
    "    # Parameters\n",
    "    lb = torch.tensor([0.0, 0.0])  # Lower bounds for x and t\n",
    "    ub = torch.tensor([1.0, 0.5])  # Upper bounds for x and t\n",
    "    Nx, Nt = 256, 100  # Discretization for x and t\n",
    "    Nu, Nf = 300, 500  # Number of boundary/initial and collocation points\n",
    "    layers = [2, 50,50, 1]  # Neural network structure\n",
    "    epochs = 50000  # Number of training epochs\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Generate training data\n",
    "    X_train, X_u_sampled = get_data(lb, ub, Nx, Nt, Nu, Nf)\n",
    "\n",
    "    # Initialize PINN\n",
    "    model = PINN(layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "   # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss, loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "        if epoch % interval == 0:\n",
    "                # 计算 NTK 并打印 NTK 矩阵的形状\n",
    "                J_u = compute_jacobian_pinn(model, X_u_sampled[:, :2])  # 只传入 x 和 y 部分\n",
    "                J_r = compute_pde_jacobian(model, X_train[:, :2])\n",
    "\n",
    "                # 计算 NTK 子矩阵\n",
    "                K_uu = torch.mm(J_u, J_u.t()).detach()\n",
    "                K_ur = torch.mm(J_u, J_r.t()).detach()\n",
    "                K_ru = torch.mm(J_r, J_u.t()).detach()\n",
    "                K_rr = torch.mm(J_r, J_r.t()).detach()\n",
    "                K = torch.vstack([\n",
    "                torch.hstack([K_uu, K_ur]),\n",
    "                torch.hstack([K_ru, K_rr])\n",
    "                ])\n",
    "                print(f\"K_uu shape: {K_uu.shape}\")\n",
    "                print(f\"K_ur shape: {K_ur.shape}\")\n",
    "                print(f\"K_ru shape: {K_ru.shape}\")\n",
    "                print(f\"K_rr shape: {K_rr.shape}\")\n",
    "                print(f\"K shape: {K.shape}\")\n",
    "                eigenvalues_uu, eigenvalues_rr, eigenvalues_k = compute_all_eigenvalues(K_uu, K_rr, K)\n",
    "                eigenvalues_uu_history.append(eigenvalues_uu)\n",
    "                eigenvalues_rr_history.append(eigenvalues_rr)\n",
    "                eigenvalues_k_history.append(eigenvalues_k)\n",
    "\n",
    "    # Generate test data\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "    u_true = exact_solution(x, t)\n",
    "\n",
    "    # Predict the solution\n",
    "    u_pred = predict(model, x, t)\n",
    "\n",
    "    # Compute L2 relative error\n",
    "    error = l2_relative_error(u_true, u_pred)\n",
    "    print(f\"L2 Relative Error: {error.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048c633",
   "metadata": {},
   "source": [
    "# SPF-PINN+NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead69b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\gputf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000, Loss: 2.349141, Loss_u: 0.229212, Loss_f: 0.015412, Loss_u_t: 0.041612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\envs\\gputf\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\dell\\Anaconda3\\envs\\gputf\\lib\\site-packages\\ipykernel_launcher.py:119: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 1000/10000, Loss: 0.593615, Loss_u: 0.058278, Loss_f: 0.004166, Loss_u_t: 0.006663\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 2000/10000, Loss: 0.527667, Loss_u: 0.051727, Loss_f: 0.003683, Loss_u_t: 0.006712\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 3000/10000, Loss: 0.271646, Loss_u: 0.024917, Loss_f: 0.020779, Loss_u_t: 0.001694\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4000/10000, Loss: 0.162207, Loss_u: 0.014276, Loss_f: 0.015498, Loss_u_t: 0.003951\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 5000/10000, Loss: 0.121761, Loss_u: 0.010536, Loss_f: 0.012613, Loss_u_t: 0.003786\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 6000/10000, Loss: 0.101516, Loss_u: 0.008150, Loss_f: 0.016169, Loss_u_t: 0.003843\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 7000/10000, Loss: 0.074848, Loss_u: 0.006570, Loss_f: 0.005587, Loss_u_t: 0.003556\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 8000/10000, Loss: 0.061642, Loss_u: 0.005342, Loss_f: 0.005025, Loss_u_t: 0.003193\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 9000/10000, Loss: 0.048947, Loss_u: 0.004101, Loss_f: 0.005095, Loss_u_t: 0.002843\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 9999/10000, Loss: 0.038087, Loss_u: 0.002994, Loss_f: 0.005641, Loss_u_t: 0.002507\n",
      "L2 Relative Error: 0.152741\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 31, 'layers.0.bias': 3, 'layers.1.weight': 528, 'layers.1.bias': 5, 'layers.2.weight': 3, 'layers.2.bias': 0}\n",
      "掩码中值为 0 的元素个数之和 570\n",
      "Epoch 0/20000, Loss: 0.038143, Loss_u: 0.002991, Loss_f: 0.005712, Loss_u_t: 0.002517\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 1000/20000, Loss: 0.029942, Loss_u: 0.002228, Loss_f: 0.005622, Loss_u_t: 0.002041\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 2000/20000, Loss: 0.029307, Loss_u: 0.001896, Loss_f: 0.008580, Loss_u_t: 0.001768\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 3000/20000, Loss: 0.024155, Loss_u: 0.001743, Loss_f: 0.005495, Loss_u_t: 0.001226\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4000/20000, Loss: 0.023056, Loss_u: 0.001655, Loss_f: 0.005530, Loss_u_t: 0.000979\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 5000/20000, Loss: 0.024860, Loss_u: 0.001592, Loss_f: 0.007965, Loss_u_t: 0.000974\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 6000/20000, Loss: 0.019169, Loss_u: 0.001538, Loss_f: 0.003138, Loss_u_t: 0.000651\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 7000/20000, Loss: 0.022254, Loss_u: 0.001489, Loss_f: 0.006733, Loss_u_t: 0.000627\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 8000/20000, Loss: 0.017609, Loss_u: 0.001442, Loss_f: 0.002688, Loss_u_t: 0.000498\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 9000/20000, Loss: 0.025622, Loss_u: 0.001388, Loss_f: 0.011075, Loss_u_t: 0.000669\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 10000/20000, Loss: 0.016308, Loss_u: 0.001318, Loss_f: 0.002693, Loss_u_t: 0.000437\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 11000/20000, Loss: 0.014433, Loss_u: 0.001217, Loss_f: 0.001931, Loss_u_t: 0.000330\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 12000/20000, Loss: 0.013377, Loss_u: 0.001084, Loss_f: 0.002231, Loss_u_t: 0.000301\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 13000/20000, Loss: 0.011296, Loss_u: 0.000928, Loss_f: 0.001772, Loss_u_t: 0.000240\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 14000/20000, Loss: 0.012285, Loss_u: 0.000759, Loss_f: 0.004424, Loss_u_t: 0.000267\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 15000/20000, Loss: 0.008010, Loss_u: 0.000601, Loss_f: 0.001807, Loss_u_t: 0.000196\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 16000/20000, Loss: 0.006663, Loss_u: 0.000478, Loss_f: 0.001711, Loss_u_t: 0.000174\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 17000/20000, Loss: 0.005882, Loss_u: 0.000384, Loss_f: 0.001857, Loss_u_t: 0.000188\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 18000/20000, Loss: 0.004696, Loss_u: 0.000312, Loss_f: 0.001420, Loss_u_t: 0.000152\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 19000/20000, Loss: 0.004100, Loss_u: 0.000261, Loss_f: 0.001342, Loss_u_t: 0.000150\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 19999/20000, Loss: 0.003636, Loss_u: 0.000222, Loss_f: 0.001267, Loss_u_t: 0.000146\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 76, 'layers.0.bias': 24, 'layers.1.weight': 1658, 'layers.1.bias': 19, 'layers.2.weight': 11, 'layers.2.bias': 0}\n",
      "掩码中值为 0 的元素个数之和 1788\n",
      "Epoch 0/10000, Loss: 0.003636, Loss_u: 0.000222, Loss_f: 0.001267, Loss_u_t: 0.000147\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 1000/10000, Loss: 0.003200, Loss_u: 0.000185, Loss_f: 0.001204, Loss_u_t: 0.000143\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 2000/10000, Loss: 0.002805, Loss_u: 0.000155, Loss_f: 0.001118, Loss_u_t: 0.000141\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 3000/10000, Loss: 0.003948, Loss_u: 0.000133, Loss_f: 0.001662, Loss_u_t: 0.000953\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4000/10000, Loss: 0.002146, Loss_u: 0.000109, Loss_f: 0.000921, Loss_u_t: 0.000132\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 5000/10000, Loss: 0.002179, Loss_u: 0.000097, Loss_f: 0.001043, Loss_u_t: 0.000168\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 6000/10000, Loss: 0.002442, Loss_u: 0.000087, Loss_f: 0.001393, Loss_u_t: 0.000183\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000/10000, Loss: 0.001696, Loss_u: 0.000079, Loss_f: 0.000783, Loss_u_t: 0.000127\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 8000/10000, Loss: 0.001572, Loss_u: 0.000073, Loss_f: 0.000721, Loss_u_t: 0.000123\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 9000/10000, Loss: 0.001466, Loss_u: 0.000068, Loss_f: 0.000676, Loss_u_t: 0.000108\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 9999/10000, Loss: 0.001552, Loss_u: 0.000067, Loss_f: 0.000671, Loss_u_t: 0.000208\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 83, 'layers.0.bias': 37, 'layers.1.weight': 1832, 'layers.1.bias': 32, 'layers.2.weight': 22, 'layers.2.bias': 0}\n",
      "掩码中值为 0 的元素个数之和 2006\n",
      "Epoch 0/5000, Loss: 0.001550, Loss_u: 0.000067, Loss_f: 0.000661, Loss_u_t: 0.000222\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 1000/5000, Loss: 0.001325, Loss_u: 0.000061, Loss_f: 0.000617, Loss_u_t: 0.000101\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 2000/5000, Loss: 0.001249, Loss_u: 0.000057, Loss_f: 0.000581, Loss_u_t: 0.000098\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 3000/5000, Loss: 0.001190, Loss_u: 0.000054, Loss_f: 0.000558, Loss_u_t: 0.000095\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4000/5000, Loss: 0.001127, Loss_u: 0.000051, Loss_f: 0.000526, Loss_u_t: 0.000093\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4999/5000, Loss: 0.001486, Loss_u: 0.000050, Loss_f: 0.000844, Loss_u_t: 0.000145\n",
      "掩码中值为 0 的元素个数： {'layers.0.weight': 85, 'layers.0.bias': 39, 'layers.1.weight': 1925, 'layers.1.bias': 35, 'layers.2.weight': 26, 'layers.2.bias': 1}\n",
      "掩码中值为 0 的元素个数之和 2111\n",
      "Epoch 0/5000, Loss: 0.001549, Loss_u: 0.000050, Loss_f: 0.000893, Loss_u_t: 0.000156\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 1000/5000, Loss: 0.001162, Loss_u: 0.000046, Loss_f: 0.000547, Loss_u_t: 0.000152\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 2000/5000, Loss: 0.000982, Loss_u: 0.000043, Loss_f: 0.000461, Loss_u_t: 0.000092\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 3000/5000, Loss: 0.000931, Loss_u: 0.000041, Loss_f: 0.000438, Loss_u_t: 0.000087\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4000/5000, Loss: 0.000891, Loss_u: 0.000038, Loss_f: 0.000422, Loss_u_t: 0.000086\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "K_uu shape: torch.Size([300, 300])\n",
      "K_ur shape: torch.Size([300, 800])\n",
      "K_ru shape: torch.Size([800, 300])\n",
      "K_rr shape: torch.Size([800, 800])\n",
      "K shape: torch.Size([1100, 1100])\n",
      "Epoch 4999/5000, Loss: 0.000856, Loss_u: 0.000036, Loss_f: 0.000407, Loss_u_t: 0.000085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n###############第四次\\nn1, m1 = 44000,1000\\nthreshold = 1e-3\\nmasks = generate_mask(weight_history, n1, m1, threshold)\\n\\nepoch2s = 5000\\ntrain_with_mask(masks, optimizer, epoch2s)\\n\\n###############第四次\\nn1, m1 = 47000,1000\\nthreshold = 1e-3\\nmasks = generate_mask(weight_history, n1, m1, threshold)\\n\\nepoch2s = 2000\\ntrain_with_mask(masks, optimizer, epoch2s)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pyDOE import lhs  # Latin Hypercube Sampling\n",
    "from torch.autograd import grad\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Define the neural network architecture\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.activation(self.layers[i](x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "# Exact solution for the Poisson equation\n",
    "def exact_solution(x, t, c=2):\n",
    "    return torch.sin(np.pi * x) * torch.cos(c * np.pi * t) + 0.5 * torch.sin(2 * c * np.pi * x) * torch.cos(4 * c * np.pi * t)\n",
    "\n",
    "# Generate training data\n",
    "def get_data(lb, ub, Nx, Nt, Nu, Nf):\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "\n",
    "    # Initial condition u(0, x) = sin(πx) + 0.5sin(4πx)\n",
    "    u_ic = torch.sin(np.pi * x[:, 0]) + 0.5 * torch.sin(4 * np.pi * x[:, 0])  # t=0\n",
    "\n",
    "    # Boundary conditions\n",
    "    u_bc_left = torch.zeros_like(t[0, :])  # x=0\n",
    "    u_bc_right = torch.zeros_like(t[-1, :])  # x=1\n",
    "\n",
    "    # Concatenate boundary/initial conditions\n",
    "    X_u = torch.cat([ \n",
    "        torch.stack([x[:, 0], t[:, 0]], dim=1),  # Initial condition\n",
    "        torch.stack([x[0, :], t[0, :]], dim=1),  # Boundary x=0\n",
    "        torch.stack([x[-1, :], t[-1, :]], dim=1)  # Boundary x=1\n",
    "    ], dim=0)\n",
    "\n",
    "    u_u = torch.cat([u_ic, u_bc_left, u_bc_right], dim=0).reshape(-1, 1)\n",
    "    X_u = torch.cat([X_u, u_u], dim=1)\n",
    "\n",
    "    # Randomly sample Nu points from X_u\n",
    "    idx = np.random.choice(X_u.shape[0], size=Nu, replace=False)\n",
    "    X_u_sampled = X_u[idx, :]\n",
    "\n",
    "    # Latin hypercube sampling for X_f (collocation points)\n",
    "    X_f = lb + (ub - lb) * torch.tensor(lhs(2, samples=Nf), dtype=torch.float32)\n",
    "\n",
    "    # Combine collocation points and sampled boundary/initial points\n",
    "    X_train = torch.cat([X_f, X_u_sampled[:, :2]], dim=0)\n",
    "\n",
    "    return X_train, X_u_sampled\n",
    "\n",
    "# Physics loss for the Poisson equation\n",
    "def physics_loss(model, X_f, c=2):\n",
    "    X_f.requires_grad_(True)\n",
    "    u = model(X_f)\n",
    "    u_t = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 1:2]\n",
    "    u_tt = grad(u_t, X_f, grad_outputs=torch.ones_like(u_t), create_graph=True)[0][:, 1:2]\n",
    "    u_x = grad(u, X_f, grad_outputs=torch.ones_like(u), create_graph=True)[0][:, 0:1]\n",
    "    u_xx = grad(u_x, X_f, grad_outputs=torch.ones_like(u_x), create_graph=True)[0][:, 0:1]\n",
    "\n",
    "    f = u_tt - c**2 * u_xx\n",
    "    return torch.mean(f**2)\n",
    "\n",
    "# L2 relative error\n",
    "def l2_relative_error(u_true, u_pred):\n",
    "    u_true_np = u_true.detach().numpy()\n",
    "    u_pred_np = u_pred.detach().numpy()\n",
    "    return np.linalg.norm(u_true_np - u_pred_np) / np.linalg.norm(u_true_np)\n",
    "def train(model, optimizer, X_train, X_u, epochs, Nf):\n",
    "    model.train()\n",
    "   \n",
    "    # Split the training data\n",
    "    X_f = X_train[:Nf, :]\n",
    "    X_u_train = X_u[:, :2]\n",
    "    u_u_train = X_u[:, 2:]\n",
    "\n",
    "    # Predict boundary/initial conditions\n",
    "    u_pred = model(X_u_train)\n",
    "    loss_u = torch.mean((u_pred - u_u_train)**2)\n",
    "\n",
    "    # Physics-informed loss\n",
    "    loss_f = physics_loss(model, X_f)\n",
    "\n",
    "    # Add initial condition for time derivative\n",
    "    # Extract x and t from X_u_train, where t = 0 for the initial condition\n",
    "    x_init = X_u_train[:, 0].reshape(-1, 1)\n",
    "    t_init = torch.zeros_like(x_init, requires_grad=True)  # Ensure t_init requires gradients\n",
    "    u_init_pred = model(torch.cat([x_init, t_init], dim=1))  # Predict u at t = 0\n",
    "    u_t_init_pred = grad(u_init_pred, t_init, grad_outputs=torch.ones_like(u_init_pred), create_graph=True)[0]  # Calculate time derivative u_t\n",
    "\n",
    "    # Loss for time derivative at t = 0, enforcing u_t(0, x) = 0\n",
    "    loss_u_t = torch.mean(u_t_init_pred**2)\n",
    "\n",
    "    return  loss_u, loss_f, loss_u_t\n",
    "##################################################################################################\n",
    "#########################################--NTK--#######################################################\n",
    "def  compute_pde_jacobian(model, X, create_graph=True, c=2):\n",
    "    \"\"\"\n",
    "    计算 KdV 方程残差的雅可比矩阵\n",
    "    model: 神经网络模型\n",
    "    X: 输入点，形状为 (N, 2)，第一列是 x，第二列是 t\n",
    "    create_graph: 是否创建计算图，默认 True\n",
    "    \"\"\"\n",
    "    X = torch.tensor(X, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    # 模型预测 u\n",
    "    u = model(X)\n",
    "\n",
    "    # 计算一阶导数 u_x, u_t\n",
    "    grad_u = torch.autograd.grad(\n",
    "        outputs=u.sum(),\n",
    "        inputs=X,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    u_x = grad_u[:, 0:1]\n",
    "    u_t = grad_u[:, 1:2]\n",
    "    \n",
    "    # 计算二阶导数 u_xx\n",
    "    u_xx = torch.autograd.grad(\n",
    "        outputs=u_x.sum(),\n",
    "        inputs=X,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, 1:2]\n",
    "    u_tt = torch.autograd.grad(\n",
    "        outputs=u_t.sum(),\n",
    "        inputs=X,\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0][:, 0:1]\n",
    "    \n",
    "    # 计算 KdV 方程残差 f = u_t + u * u_x + u_xxx\n",
    "    f = u_tt -c**2*u_xx\n",
    "\n",
    "    # 计算残差的雅可比矩阵\n",
    "    jacobian_list = []\n",
    "    for i in range(f.size(0)):\n",
    "        grad_outputs = torch.ones_like(f[i])\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=f[i],\n",
    "            inputs=model.parameters(),\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        # 处理 None 的梯度\n",
    "        valid_grads = [g if g is not None else torch.zeros_like(p) \n",
    "                       for g, p in zip(grads, model.parameters())]\n",
    "        jacobian_list.append(torch.cat([g.view(-1) for g in valid_grads]))\n",
    "\n",
    "    return torch.stack(jacobian_list)\n",
    "def  compute_jacobian_pinn(model, X_u, create_graph=True):\n",
    "\n",
    "    X_u = torch.tensor(X_u, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    # 模型预测初边值条件的 u\n",
    "    u = model(X_u)\n",
    "    \n",
    "    # 计算初边值条件的雅可比矩阵\n",
    "    jacobian_list = []\n",
    "    for i in range(u.size(0)):\n",
    "        grad_outputs = torch.ones_like(u[i])\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=u[i],\n",
    "            inputs=model.parameters(),\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        # 处理 None 的梯度\n",
    "        valid_grads = [g if g is not None else torch.zeros_like(p) \n",
    "                       for g, p in zip(grads, model.parameters())]\n",
    "        jacobian_list.append(torch.cat([g.view(-1) for g in valid_grads]))\n",
    "    \n",
    "    return torch.stack(jacobian_list)\n",
    "\n",
    "def compute_all_eigenvalues(K_uu, K_rr, K):\n",
    "\n",
    "    # 计算Kuu的特征值\n",
    "    eigenvalues_uu = np.sort(np.real(np.linalg.eigvals(K_uu.detach().numpy())))[::-1]\n",
    "    \n",
    "    # 计算Krr的特征值\n",
    "    eigenvalues_rr = np.sort(np.real(np.linalg.eigvals(K_rr.detach().numpy())))[::-1]\n",
    "    \n",
    "    # 计算完整K矩阵的特征值\n",
    "    eigenvalues_k = np.sort(np.real(np.linalg.eigvals(K.detach().numpy())))[::-1]\n",
    "    \n",
    "    return eigenvalues_uu, eigenvalues_rr, eigenvalues_k\n",
    "###########################################生成mask矩阵################################\n",
    "def generate_mask(weight_history, n, m, threshold):\n",
    "    weight_diffs = {}\n",
    "    for name, weights in weight_history.items():\n",
    "        if len(weights) >= n + m - 1:\n",
    "            weight_n = np.array(weights[n - 1])\n",
    "            weight_n_m = np.array(weights[n + m - 1])\n",
    "            weight_diffs[name] = np.abs(weight_n - weight_n_m)\n",
    "        else:\n",
    "            print(f\"Warning: Not enough weights for {name} to compute weight difference at n={n} and m={m}\")\n",
    "\n",
    "    masks = {}\n",
    "    for name, param in model .named_parameters():\n",
    "        weight_diff = weight_diffs.get(name, None)\n",
    "        if weight_diff is not None:\n",
    "            mask = torch.ones_like(param.data)\n",
    "            mask.view(-1)[weight_diff.flatten() < threshold] = 0\n",
    "            masks[name] = mask\n",
    "        else:\n",
    "            masks[name] = torch.ones_like(param.data)\n",
    "    # 计算掩码中值为 0 的元素个数\n",
    "    num_zeros = {}\n",
    "    total_zeros = 0\n",
    "    for name, mask in masks.items():\n",
    "        num_zeros[name] = torch.sum(torch.eq(mask, 0)).item()\n",
    "        total_zeros += num_zeros[name]  # 累加每个掩码中值为 0 的元素个数\n",
    "    print(\"掩码中值为 0 的元素个数：\", num_zeros)\n",
    "    print('掩码中值为 0 的元素个数之和',total_zeros)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "# 封装训练过程的函数\n",
    "def train_with_mask(masks, optimizer, epochs):           \n",
    "       for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "        loss = 10*loss_u + loss_f + loss_u_t\n",
    "        loss.backward()\n",
    "        for name, param in model.named_parameters():\n",
    "            weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "        for name, param in model.named_parameters():\n",
    "            # print(f\"Name: {name}, param.grad: {param.grad}, masks[name]: {masks[name]}\")\n",
    "            if param.requires_grad and masks[name] is not None:  # 确保掩码张量不为 None\n",
    "                if param.grad is not None:  # 检查梯度是否为 None\n",
    "                    param.grad *= masks[name].detach()\n",
    "        optimizer.step()\n",
    "        if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "        if epoch % interval == 0:\n",
    "                # 计算 NTK 并打印 NTK 矩阵的形状\n",
    "                J_u = compute_jacobian_pinn(model, X_u_sampled[:, :2])  # 只传入 x 和 y 部分\n",
    "                J_r = compute_pde_jacobian(model, X_train[:, :2])\n",
    "\n",
    "                # 计算 NTK 子矩阵\n",
    "                K_uu = torch.mm(J_u, J_u.t()).detach()\n",
    "                K_ur = torch.mm(J_u, J_r.t()).detach()\n",
    "                K_ru = torch.mm(J_r, J_u.t()).detach()\n",
    "                K_rr = torch.mm(J_r, J_r.t()).detach()\n",
    "                K = torch.vstack([\n",
    "                torch.hstack([K_uu, K_ur]),\n",
    "                torch.hstack([K_ru, K_rr])\n",
    "                ])\n",
    "                print(f\"K_uu shape: {K_uu.shape}\")\n",
    "                print(f\"K_ur shape: {K_ur.shape}\")\n",
    "                print(f\"K_ru shape: {K_ru.shape}\")\n",
    "                print(f\"K_rr shape: {K_rr.shape}\")\n",
    "                print(f\"K shape: {K.shape}\")\n",
    "                eigenvalues_uu, eigenvalues_rr, eigenvalues_k1 = compute_all_eigenvalues(K_uu, K_rr, K)\n",
    "                eigenvalues_uu_history.append(eigenvalues_uu)\n",
    "                eigenvalues_rr_history.append(eigenvalues_rr)\n",
    "                eigenvalues_k_history1.append(eigenvalues_k1)\n",
    "\n",
    "\n",
    "\n",
    "# Predict function\n",
    "def predict(model, x, t):\n",
    "    model.eval()\n",
    "    X = torch.stack([x.reshape(-1), t.reshape(-1)], dim=1)\n",
    "    u_pred = model(X)\n",
    "    return u_pred.reshape(x.shape)\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "            # 记录不同矩阵的特征值演化\n",
    "    eigenvalues_uu_history = []\n",
    "    eigenvalues_rr_history = []\n",
    "    eigenvalues_k_history1 = []\n",
    "    interval = 500\n",
    "    # Parameters\n",
    "    lb = torch.tensor([0.0, 0.0])  # Lower bounds for x and t\n",
    "    ub = torch.tensor([1.0, 0.5])  # Upper bounds for x and t\n",
    "    Nx, Nt = 256, 100  # Discretization for x and t\n",
    "    Nu, Nf = 300, 500  # Number of boundary/initial and collocation points\n",
    "    layers = [2, 50, 50,  1]  # Neural network structure\n",
    "    epochs = 10000  # Number of training epochs\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    # Generate training data\n",
    "    X_train, X_u_sampled = get_data(lb, ub, Nx, Nt, Nu, Nf)\n",
    "\n",
    "    # Initialize PINN\n",
    "    model = PINN(layers)\n",
    "    weight_history = {name: [] for name, _ in model.named_parameters()}\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "   # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        #loss, loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "        loss_u, loss_f, loss_u_t = train(model, optimizer, X_train, X_u_sampled, epochs, Nf)\n",
    "        loss = 10*loss_u + loss_f + loss_u_t\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for name, param in model.named_parameters():\n",
    "            weight_history[name].append(param.clone().detach().numpy().flatten())\n",
    "        if epoch % 1000 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.6f}, Loss_u: {loss_u.item():.6f}, Loss_f: {loss_f.item():.6f}, Loss_u_t: {loss_u_t.item():.6f}\")\n",
    "        if epoch % interval == 0:\n",
    "                # 计算 NTK 并打印 NTK 矩阵的形状\n",
    "                J_u = compute_jacobian_pinn(model, X_u_sampled[:, :2])  # 只传入 x 和 y 部分\n",
    "                J_r = compute_pde_jacobian(model, X_train[:, :2])\n",
    "\n",
    "                # 计算 NTK 子矩阵\n",
    "                K_uu = torch.mm(J_u, J_u.t()).detach()\n",
    "                K_ur = torch.mm(J_u, J_r.t()).detach()\n",
    "                K_ru = torch.mm(J_r, J_u.t()).detach()\n",
    "                K_rr = torch.mm(J_r, J_r.t()).detach()\n",
    "                K = torch.vstack([\n",
    "                torch.hstack([K_uu, K_ur]),\n",
    "                torch.hstack([K_ru, K_rr])\n",
    "                ])\n",
    "                print(f\"K_uu shape: {K_uu.shape}\")\n",
    "                print(f\"K_ur shape: {K_ur.shape}\")\n",
    "                print(f\"K_ru shape: {K_ru.shape}\")\n",
    "                print(f\"K_rr shape: {K_rr.shape}\")\n",
    "                print(f\"K shape: {K.shape}\")\n",
    "                eigenvalues_uu, eigenvalues_rr, eigenvalues_k1 = compute_all_eigenvalues(K_uu, K_rr, K)\n",
    "                eigenvalues_uu_history.append(eigenvalues_uu)\n",
    "                eigenvalues_rr_history.append(eigenvalues_rr)\n",
    "                eigenvalues_k_history1.append(eigenvalues_k1)\n",
    "\n",
    "\n",
    "    # Generate test data\n",
    "    x = torch.linspace(lb[0], ub[0], Nx)\n",
    "    t = torch.linspace(lb[1], ub[1], Nt)\n",
    "    x, t = torch.meshgrid(x, t, indexing=\"ij\")\n",
    "    u_true = exact_solution(x, t)\n",
    "\n",
    "    # Predict the solution\n",
    "    u_pred = predict(model, x, t)\n",
    "\n",
    "    # Compute L2 relative error\n",
    "    error = l2_relative_error(u_true, u_pred)\n",
    "    print(f\"L2 Relative Error: {error.item():.6f}\")\n",
    "##############第一次\n",
    "n1, m1 = 9000,1000\n",
    "threshold =1e-3\n",
    "masks = generate_mask(weight_history, n1, m1, threshold)\n",
    "\n",
    "epoch2s = 20000\n",
    "train_with_mask(masks, optimizer, epoch2s)\n",
    "\n",
    "\n",
    "###############第二次\n",
    "n1, m1 = 29000,1000\n",
    "threshold = 1e-3\n",
    "masks = generate_mask(weight_history, n1, m1, threshold)\n",
    "\n",
    "epoch2s = 10000\n",
    "train_with_mask(masks, optimizer, epoch2s)\n",
    "\n",
    "###############第三次\n",
    "n1, m1 = 39000,1000\n",
    "threshold = 1e-3\n",
    "masks = generate_mask(weight_history, n1, m1, threshold)\n",
    "\n",
    "epoch2s = 5000\n",
    "train_with_mask(masks, optimizer, epoch2s)\n",
    "###############第四次\n",
    "n1, m1 = 44000,1000\n",
    "threshold = 1e-3\n",
    "masks = generate_mask(weight_history, n1, m1, threshold)\n",
    "\n",
    "epoch2s = 5000\n",
    "train_with_mask(masks, optimizer, epoch2s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773315c",
   "metadata": {},
   "source": [
    "# NTK-comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9635cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 参数设置\n",
    "start_epoch = 12500\n",
    "step_interval = 4  # 每隔 4 轮计算一次\n",
    "interval = 500  # 训练步长，影响 epoch 计算\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "eigenvalues_k_history1 = np.array(eigenvalues_k_history1)\n",
    "eigenvalues_k_history = np.array(eigenvalues_k_history)\n",
    "\n",
    "# 计算数量信息eigenvalues_k_history\n",
    "num_snapshots1 = len(eigenvalues_k_history1)\n",
    "num_snapshots2 = len(eigenvalues_k_history)\n",
    "assert num_snapshots1 == num_snapshots2, \"两组特征值历史长度不匹配\"\n",
    "\n",
    "# 存储计算结果\n",
    "var_over_time1, mean_over_time1, var_over_time2, mean_over_time2 = [], [], [], []\n",
    "epochs = []\n",
    "\n",
    "# 计算滑动窗口的方差和均值\n",
    "for i in range(num_snapshots1 - step_interval):\n",
    "    epoch = (i + 1) * interval\n",
    "    if epoch >= start_epoch:\n",
    "        # 计算第一组\n",
    "        eigenvalues_segment1 = eigenvalues_k_history1[i : i + step_interval]\n",
    "        eigenvar1 = np.var(eigenvalues_segment1, axis=0)\n",
    "        eigenmean1 = np.mean(eigenvalues_segment1, axis=0)\n",
    "        valid_indices1 = eigenmean1 >= 1e-3\n",
    "        filtered_eigenmean1 = eigenmean1[valid_indices1]\n",
    "\n",
    "        # 计算第二组\n",
    "        eigenvalues_segment2 = eigenvalues_k_history[i : i + step_interval]\n",
    "        eigenvar2 = np.var(eigenvalues_segment2, axis=0)\n",
    "        eigenmean2 = np.mean(eigenvalues_segment2, axis=0)\n",
    "        valid_indices2 = eigenmean2 >= 1e-3\n",
    "        filtered_eigenmean2 = eigenmean2[valid_indices2]\n",
    "\n",
    "        # 计算整体均值和方差\n",
    "        var_over_time1.append(np.mean(eigenvar1))\n",
    "        mean_over_time1.append(np.mean(filtered_eigenmean1) if len(filtered_eigenmean1) > 0 else 0)\n",
    "\n",
    "        var_over_time2.append(np.mean(eigenvar2))\n",
    "        mean_over_time2.append(np.mean(filtered_eigenmean2) if len(filtered_eigenmean2) > 0 else 0)\n",
    "\n",
    "        epochs.append(epoch)\n",
    "\n",
    "# **第一张图：方差随 Epoch 变化**\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, var_over_time1, marker='s', linestyle='-', color='r',  markerfacecolor='none',label=\"SPF-PINN: Variance of Eigenvalues\")\n",
    "plt.plot(epochs, var_over_time2, marker='o', linestyle='--', color='b',markersize=5,label=\"PINN: Variance of Eigenvalues\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Variance of Eigenvalues\")\n",
    "plt.title(\"Comparison of Variance of NTK Eigenvalues Over Training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "# **第二张图：均值随 Epoch 变化**\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, mean_over_time1, marker='s', linestyle='-', color='r',  markerfacecolor='none',label=\"SPF-PINN: Mean of Eigenvalues\")\n",
    "plt.plot(epochs, mean_over_time2, marker='o', linestyle='--', color='b', \n",
    "         markersize=5, label=\"PINN: Mean of Eigenvalues\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean of Eigenvalues\")\n",
    "plt.title(\"Comparison of Mean of NTK Eigenvalues Over Training\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27955f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
